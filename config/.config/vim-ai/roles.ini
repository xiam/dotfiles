# local models

[phi]
options.endpoint_url = https://litellm.local.xiam.dev/ollama/v1/chat/completions
options.model = phi4-reasoning:14b

[deepseek]
options.endpoint_url = https://litellm.local.xiam.dev/ollama/v1/chat/completions
options.model = deepseek-coder-v2:16b

[llama]
options.endpoint_url = https://litellm.local.xiam.dev/ollama/v1/chat/completions
options.model = codellama:34b

[qwen]
options.endpoint_url = https://litellm.local.xiam.dev/ollama/v1/chat/completions
options.model = qwen2.5-coder:14b

[codestral]
options.endpoint_url = https://litellm.local.xiam.dev/ollama/v1/chat/completions
options.model = codestral:22b

# commercial models

[gemini]
options.model = gemini/gemini-2.5-pro

[gemini-flash]
options.model = gemini/gemini-2.5-flash

[claude]
options.model = anthropic/claude-sonnet-4-5-20250929

[claude-opus]
options.model = anthropic/claude-opus-4-1-20250805

[claude-haiku]
options.model = anthropic/claude-haiku-4-5-20251001

[gpt5]
options.model = openai/gpt-5-2025-08-07

[gpt5-mini]
options.model = openai/gpt-5-mini-2025-08-07
